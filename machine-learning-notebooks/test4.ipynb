{
 "metadata": {
  "name": "",
  "signature": "sha256:60f58908cbe9b64a4cbbd7e2ef5f2570eec69373c35ce5346c51ee68f9b72c7a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import tensorflow as tf\n",
      "if tf.test.gpu_device_name():\n",
      "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
      "else:\n",
      "    print(\"Please install GPU version of TF\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Default GPU Device: /device:GPU:0\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
        "  from ._conv import register_converters as _register_converters\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.image import imread"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import numpy as np\n",
      "# from sklearn.preprocessing import OneHotEncoder\n",
      "labels = os.listdir('data/data/train')\n",
      "print(labels)\n",
      "# labels = np.array(labels)\n",
      "# # x = labels.reshape(-1,1)\n",
      "# ohe = OneHotEncoder()\n",
      "# ohe.fit(labels.reshape(-1,1))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['trash', 'glass', 'plastic', 'metal', 'paper_based']\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# order is:\n",
      "order = ['glass', 'metal', 'paper_based', 'plastic', 'trash']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from keras.preprocessing.image import ImageDataGenerator\n",
      "from pprint import pprint\n",
      "from keras.preprocessing.image import ImageDataGenerator\n",
      "# create generator \n",
      "# datagen = ImageDataGenerator(rescale = 1.0/255.0, width_shift_range=10.0, vertical_flip=True, height_shift_range = 10.0, rotation_range = 10.0)\n",
      "datagen = ImageDataGenerator(rescale = 1.0, width_shift_range=10.0, vertical_flip=True, height_shift_range = 10.0, rotation_range = 10.0)\n",
      "\n",
      "# prepare an iterators for each dataset\n",
      "train_data = datagen.flow_from_directory('data/data-merged-with-real-world/train', class_mode='categorical', batch_size = 32, target_size=(256,256), shuffle=False)\n",
      "val_data = datagen.flow_from_directory('data/data-merged-with-real-world/val', class_mode='categorical', target_size=(256,256), shuffle=False)\n",
      "# val_it = datagen.flow_from_directory('data/validation/', class_mode='binary')\n",
      "# test_it = datagen.flow_from_directory('data/test/', class_mode='binary')\n",
      "# confirm the iterator works\n",
      "# pprint(train_data.filenames[:5])\n",
      "# batchX, batchy = train_data.next()\n",
      "# print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
      "# for batchX_one, batchy_one in zip(batchX, batchy):\n",
      "#     print(batchX_one.shape)\n",
      "#     print(batchy_one)\n",
      "# print(train_data[0][0])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.applications.vgg16 import VGG16\n",
      "from keras.applications.resnet import *\n",
      "from keras.models import *\n",
      "# base = VGG16(include_top = False, weights='imagenet', input_shape = (256,256,3))\n",
      "\n",
      "\n",
      "#testing resnet34 stuff\n",
      "# from classification_models.resnet import ResNet34\n",
      "base = ResNet152(input_shape=(256, 256, 3), weights='imagenet', include_top=False)\n",
      "\n",
      "# model2 = Sequential()\n",
      "# base = ResNet50(include_top = False, weights='imagenet', input_shape = (256,256,3))\n",
      "# for layer in base.layers:\n",
      "#     layer.trainable = False\n",
      "# model2.add(base)\n",
      "# model2.summary()\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Using bottleneck feature for performance\n",
      "# import pickle as pkl\n",
      "import math\n",
      "nb_train_samples = len(train_data.filenames)  \n",
      "num_classes = len(train_data.class_indices)  \n",
      "\n",
      "# predict_size_train = int(math.ceil(nb_train_samples / 32))  \n",
      "\n",
      "bottleneck_features_train = base.predict_generator(train_data)\n",
      "# pkl.dump(bottleneck_features_train, open('saved_features/bottleneck_features_train.pkl', 'wb'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nb_val_samples = len(val_data.filenames)  \n",
      "num_classes = len(val_data.class_indices)  \n",
      "\n",
      "# predict_size_validation = int(math.ceil(nb_val_samples / 32))  \n",
      "\n",
      "bottleneck_features_val = base.predict_generator(val_data)\n",
      "# pkl.dump(bottleneck_features_val, open('saved_features/bottleneck_features_val.pkl', 'wb'))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.utils import to_categorical\n",
      "# datagen2 = ImageDataGenerator(rescale=1./255)\n",
      "datagen2 = ImageDataGenerator(rescale=1.)\n",
      "generator_top = datagen2.flow_from_directory(  \n",
      "        'data/data-merged-with-real-world/train',  \n",
      "        target_size=(256, 256),  \n",
      "        batch_size=32,  \n",
      "        class_mode='categorical',  \n",
      "        shuffle=False)  \n",
      "   \n",
      "# nb_train_samples = len(generator_top.filenames)  \n",
      "# num_classes = len(generator_top.class_indices)  \n",
      "\n",
      "# train_data = np.load('bottleneck_features_train.npy')  \n",
      "train_data = bottleneck_features_train\n",
      "# get the class lebels for the training data, in the original order  \n",
      "train_labels = generator_top.classes  \n",
      "\n",
      "# convert the training labels to categorical vectors  \n",
      "train_labels = to_categorical(train_labels, num_classes=len(labels)) \n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# print(generator_top.classes)\n",
      "# print(train_labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "generator_top = datagen2.flow_from_directory(  \n",
      "         'data/data-merged-with-real-world/val',  \n",
      "         target_size=(256, 256),  \n",
      "         batch_size=32,  \n",
      "         class_mode=None,  \n",
      "         shuffle=False)  \n",
      "   \n",
      "#  nb_validation_samples = len(generator_top.filenames)  \n",
      "   \n",
      "validation_data = bottleneck_features_val\n",
      "\n",
      "validation_labels = generator_top.classes  \n",
      "validation_labels = to_categorical(validation_labels, num_classes=len(labels))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# print(bottleneck_features_train[1][:,:,3])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# model = Sequential()  \n",
      "# model.add(Flatten(input_shape=train_data.shape[1:]))  \n",
      "# model.add(Dense(256, activation='relu'))  \n",
      "# model.add(Dropout(0.5))  \n",
      "# model.add(Dense(num_classes, activation='sigmoid'))  \n",
      "   \n",
      "# model.compile(optimizer='rmsprop',  \n",
      "#           loss='categorical_crossentropy', metrics=['accuracy'])  \n",
      "\n",
      "# history = model.fit(train_data, train_labels,  \n",
      "#       epochs=epochs,  \n",
      "#       batch_size=batch_size,  \n",
      "#       validation_data=(validation_data, validation_labels))  \n",
      "\n",
      "# model.save_weights(top_model_weights_path)  \n",
      "\n",
      "# (eval_loss, eval_accuracy) = model.evaluate(  \n",
      "#  validation_data, validation_labels, batch_size=batch_size, verbose=1)\n",
      "\n",
      "# print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))  \n",
      "# print(\"[INFO] Loss: {}\".format(eval_loss))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# model2 = load_model('models/resnet152/2020-01-09-21:32:18.hdf5')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Note: Now we're using this code!!!\n",
      "\n",
      "\n",
      "# Make changes to the Dropout rate before running this!!!!!!\n",
      "from keras.layers import *\n",
      "model2 = Sequential()\n",
      "model2.add(Flatten(input_shape=train_data.shape[1:]))\n",
      "model2.add(Dense(128, activation='relu'))\n",
      "model2.add(Dropout(0.25))\n",
      "model2.add(Dense(64, activation='relu'))\n",
      "model2.add(Dropout(0.25))\n",
      "model2.add(Dense(32, activation='relu'))\n",
      "model2.add(Dense(len(labels), activation='softmax'))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.optimizers import *\n",
      "learning_rate = 5.13e-03\n",
      "epochs = 500\n",
      "decay = learning_rate/epochs\n",
      "opt = Adam(lr=learning_rate, decay = decay)\n",
      "model2.compile(optimizer=opt,\n",
      "              loss='categorical_crossentropy',\n",
      "              metrics=['accuracy'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# from keras.callbacks import TensorBoard\n",
      "# import keras\n",
      "# from datetime import datetime\n",
      "\n",
      "# now = str(datetime.now())\n",
      "# timestamp = now[:10]+'-'+now[11:19]\n",
      "\n",
      "# log_dir = 'logs/'+'resnet34/'+timestamp\n",
      "\n",
      "# if not os.path.exists(log_dir):\n",
      "#     os.mkdir(log_dir)\n",
      "\n",
      "# tb_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from datetime import datetime\n",
      "now = str(datetime.now())\n",
      "timestamp = now[:10]+'-'+now[11:19]\n",
      "\n",
      "model_dir = 'models/'+'resnet152/'+timestamp+'.hdf5'\n",
      "# filepath = 'weights.best.hdf5'\n",
      "checkpoint = ModelCheckpoint(model_dir, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Note: change initial_epoch if needed\n",
      "model2.fit(train_data, train_labels, epochs=500, batch_size=32, validation_data =(validation_data, validation_labels), callbacks = [checkpoint]\n",
      "           , initial_epoch=0)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# for layer in base.layers:\n",
      "#     layer.trainable = False\n",
      "# model = Sequential()\n",
      "# model.add(base)\n",
      "# model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# even more cheating!?\n",
      "\n",
      "from keras.utils import to_categorical\n",
      "from keras.callbacks import ModelCheckpoint\n",
      "from datetime import datetime\n",
      "\n",
      "# datagen2 = ImageDataGenerator(rescale=1./255)\n",
      "datagen2 = ImageDataGenerator(rescale=1.)\n",
      "generator_top = datagen2.flow_from_directory(  \n",
      "        'data/data-merged-with-real-world/train',  \n",
      "        target_size=(256, 256),  \n",
      "        batch_size=32,  \n",
      "        class_mode='categorical',  \n",
      "        shuffle=False)  \n",
      "   \n",
      "# nb_train_samples = len(generator_top.filenames)  \n",
      "# num_classes = len(generator_top.class_indices)  \n",
      "\n",
      "# train_data = np.load('bottleneck_features_train.npy')  \n",
      "train_data = bottleneck_features_train\n",
      "# get the class lebels for the training data, in the original order  \n",
      "train_labels = generator_top.classes  \n",
      "\n",
      "# convert the training labels to categorical vectors  \n",
      "train_labels = to_categorical(train_labels, num_classes=len(labels))\n",
      "\n",
      "# print(generator_top.classes)\n",
      "# print(train_labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "generator_top = datagen2.flow_from_directory(  \n",
      "         'data/data-merged-with-real-world/val',  \n",
      "         target_size=(256, 256),  \n",
      "         batch_size=32,  \n",
      "         class_mode=None,  \n",
      "         shuffle=False)  \n",
      "   \n",
      "#  nb_validation_samples = len(generator_top.filenames)  \n",
      "   \n",
      "validation_data = bottleneck_features_val\n",
      "\n",
      "validation_labels = generator_top.classes  \n",
      "validation_labels = to_categorical(validation_labels, num_classes=len(labels))\n",
      "\n",
      "\n",
      "now = str(datetime.now())\n",
      "timestamp = now[:10]+'-'+now[11:19]\n",
      "\n",
      "model_dir = 'models/'+'resnet152/'+timestamp+'.hdf5'\n",
      "# filepath = 'weights.best.hdf5'\n",
      "checkpoint = ModelCheckpoint(model_dir, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Note: change initial_epoch if needed\n",
      "model2.fit(train_data, train_labels, epochs=500, batch_size=32, validation_data =(validation_data, validation_labels), callbacks = [checkpoint]\n",
      "           , initial_epoch=0)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.preprocessing.image import *"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
        "  from ._conv import register_converters as _register_converters\n",
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Note best till now:\n",
      "# 2020-01-11-04:14:31.hdf5\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# testing!?\n",
      "from keras.models import load_model\n",
      "model2 = load_model('models/resnet152/2020-01-11-04:14:31.hdf5')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.preprocessing.image import *\n",
      "datagen = ImageDataGenerator()\n",
      "generator = datagen.flow_from_directory('data/data-real-world', class_mode='categorical', shuffle=False)\n",
      "\n",
      "predictions = base.predict_generator(generator)\n",
      "print(predictions.shape)\n",
      "# y = generator.classes\n",
      "# model2.evaluate(x=predictions, y=y)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Found 47 images belonging to 5 classes.\n",
        "(47, 8, 8, 2048)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "y = np.array(generator.classes)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "b = np.zeros((predictions.shape[0], 5))\n",
      "# print(b)\n",
      "for i, yy in enumerate(y):\n",
      "    b[i][yy] = 1.\n",
      "# print(b)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "model2.evaluate(x=predictions, y=b)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "32/47 [===================>..........] - ETA: 0s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "47/47 [==============================] - 1s 11ms/step\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "[0.33376208264777, 0.957446813583374]"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "predictions2 = model2.predict(predictions)\n",
      "\n",
      "filenames = generator.filenames\n",
      "i = 0\n",
      "print(order)\n",
      "for prediction2, yy in zip(predictions2, y):\n",
      "    print(order[np.argmax(prediction2)]+' '+order[yy]+' '+filenames[i])\n",
      "#     print('probs: '+str(prediction2))\n",
      "    i+=1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['glass', 'metal', 'paper_based', 'plastic', 'trash']\n",
        "metal metal metal/MVIMG_20200110_223923.jpg\n",
        "plastic metal metal/MVIMG_20200110_223929.jpg\n",
        "metal metal metal/MVIMG_20200110_223935.jpg\n",
        "metal metal metal/MVIMG_20200110_223943.jpg\n",
        "metal metal metal/MVIMG_20200110_223952.jpg\n",
        "metal metal metal/MVIMG_20200110_223957.jpg\n",
        "metal metal metal/MVIMG_20200110_224001.jpg\n",
        "metal metal metal/MVIMG_20200110_224006.jpg\n",
        "metal metal metal/WhatsApp Image 2020-01-11 at 2.10.09 AM.jpeg\n",
        "metal metal metal/four cans.jpeg\n",
        "metal metal metal/three-cans.jpeg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_205541.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210745.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210753.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210803.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210807.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210915.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210933.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210936.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210941.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210945.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_210948.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_211307.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_211308.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_211315.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212628.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212631.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212635.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212637.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212643.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212647.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212754.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212818.jpg\n",
        "paper_based paper_based paper_based/MVIMG_20200110_212824.jpg\n",
        "paper_based paper_based paper_based/most-imp-image.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_210831.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_210835.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_210842.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_210851.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_210858.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_210901.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_210903.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_213149.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_213153.jpg\n",
        "plastic plastic plastic/MVIMG_20200110_213156.jpg\n",
        "plastic plastic plastic/most-imp-img.jpg\n",
        "metal plastic plastic/wires.jpeg\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Ignore this code:\n",
      "\n",
      "from keras.layers import *\n",
      "# print(len(labels))\n",
      "# model = model2\n",
      "model.add(Flatten())\n",
      "# model.add(Dropout(0.25))\n",
      "model.add(Dense(32,activation='relu'))\n",
      "# model.add(Dropout(0.30))\n",
      "model.add(Dense(16, activation='relu'))\n",
      "# model.add(Dropout(0.50))\n",
      "# model.add(Dense(128, activation='relu'))\n",
      "model.add(Dense(len(labels),activation='softmax'))\n",
      "model.summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from keras.optimizers import *\n",
      "opt = Adam(lr=5.13e-03)\n",
      "model.compile(optimizer=opt,\n",
      "              loss='categorical_crossentropy',\n",
      "              metrics=['accuracy'])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# import cv2\n",
      "# dir_name = 'data/data/train/paper_based'\n",
      "# img_name = 'paper1.jpg'\n",
      "# test_image = cv2.imread(dir_name+'/'+img_name)\n",
      "# new_shape = (256, 256)\n",
      "# resized_image = cv2.resize(test_image, new_shape)\n",
      "# resized_image = resized_image/255.0\n",
      "# resized_images = np.array([resized_image])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# activations!!\n",
      "\n",
      "# layer_outputs = [layer.output for layer in model.layers[1:]]\n",
      "# activation_model = Model(inputs=model.input,outputs=layer_outputs)\n",
      "# activations = activation_model.predict(resized_images)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# layer_names = []\n",
      "# for layer in model.layers:\n",
      "#     layer_names.append(layer.name) # Names of the layers, so you can have them as part of your plot\n",
      "    \n",
      "# images_per_row = 16\n",
      "# print(layer_names)\n",
      "# layer_names=layer_names[1:]\n",
      "# print(len(layer_names))\n",
      "# print(len(activations))\n",
      "# for layer_name, layer_activation in zip(layer_names, activations): # Displays the feature maps\n",
      "#     print(layer_name)\n",
      "#     n_features = layer_activation.shape[-1] # Number of features in the feature map\n",
      "#     size = layer_activation.shape[1] #The feature map has shape (1, size, size, n_features).\n",
      "#     n_cols = n_features // images_per_row # Tiles the activation channels in this matrix\n",
      "#     print('size: {} n_cols: {} images_per_row: {} size * n_cols: {} images_per_row * size: {}'.format(size, n_cols, images_per_row, size * n_cols, images_per_row * size))\n",
      "#     display_grid = np.zeros((size * n_cols, images_per_row * size))\n",
      "#     for col in range(n_cols): # Tiles each filter into a big horizontal grid\n",
      "#         for row in range(images_per_row):\n",
      "#             print('layer_name: {} row: {} col: {}'.format(layer_name, row, col))\n",
      "#             channel_image = layer_activation[0,\n",
      "#                                              :, :,\n",
      "#                                              col * images_per_row + row]\n",
      "#             channel_image -= channel_image.mean() # Post-processes the feature to make it visually palatable\n",
      "#             channel_image /= channel_image.std()\n",
      "#             channel_image *= 64\n",
      "#             channel_image += 128\n",
      "#             channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
      "#             display_grid[col * size : (col + 1) * size, # Displays the grid\n",
      "#                          row * size : (row + 1) * size] = channel_image\n",
      "#     scale = 1. / size\n",
      "#     plt.figure(figsize=(scale * display_grid.shape[1],\n",
      "#                         scale * display_grid.shape[0]))\n",
      "#     plt.title(layer_name)\n",
      "#     plt.grid(False)\n",
      "#     plt.imshow(display_grid, aspect='auto', cmap='viridis')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# from keras.models import Model\n",
      "# layer_outputs = [layer.output for layer in model.layers]\n",
      "# activation_model = Model(inputs=model.input, outputs=layer_outputs)\n",
      "# activations = activation_model.predict(X_train[10].reshape(1,28,28,1))\n",
      " \n",
      "# def display_activation(activations, col_size, row_size, act_index): \n",
      "#     activation = activations[act_index]\n",
      "#     activation_index=0\n",
      "#     fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*2.5,col_size*1.5))\n",
      "#     for row in range(0,row_size):\n",
      "#         for col in range(0,col_size):\n",
      "#             ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n",
      "#             activation_index += 1\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# display_activation(activations, 8, 8, 1)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# import tensorflow as tf\n",
      "\n",
      "# assert tf.test.is_gpu_available()\n",
      "# assert tf.test.is_built_with_cuda()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# print(tf.test.is_built_with_cuda())\n",
      "# print(tf.test.gpu_device_name())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# model = load_model('models/model7.h5')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# model.fit_generator(train_data, epochs = 5, validation_data = val_data, steps_per_epoch=72)\n",
      "# model.save(\"models/model11.h5\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from keras.models import load_model\n",
      "model2 = load_model('models/resnet152/2020-01-09-21:32:18.hdf5')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#check whether you're predicting the same thing everytime!!\n",
      "import cv2\n",
      "import os\n",
      "import numpy as np\n",
      "from keras.preprocessing.image import *\n",
      "\n",
      "resized_images = []\n",
      "dir_name = 'data/data/test'\n",
      "for img_name in os.listdir(dir_name)[:20]:\n",
      "    print('image_name: {}'.format(img_name))\n",
      "#     test_image = cv2.imread(dir_name+'/'+img_name)\n",
      "    \n",
      "#     img_file_path = 'data/data/train/glass/glass100.jpg'\n",
      "    img_file_path = dir_name+'/'+img_name\n",
      "    img = load_img(img_file_path, target_size=(256, 256))\n",
      "    test_image = img\n",
      "#     print(type(img))\n",
      "#     print(img.format)\n",
      "#     print(img.mode)\n",
      "#     print(img.size)\n",
      "\n",
      "    # img.show()\n",
      "    img1 = img_to_array(img)\n",
      "\n",
      "#     new_shape = (256, 256)\n",
      "#     resized_image = cv2.resize(test_image, new_shape)\n",
      "#     resized_image = resized_image/255.0\n",
      "    resized_images.append(img1)\n",
      "\n",
      "test_images = np.array(resized_images)\n",
      "bottleneck_test = base.predict(test_images)\n",
      "\n",
      "predictions = model2.predict(bottleneck_test)\n",
      "predictions2 = [prediction.argmax() for prediction in predictions]\n",
      "predictions2 = [order[prediction2] for prediction2 in predictions2]\n",
      "print(predictions2)\n",
      "# print(predictions)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print(labels)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# model.evaluate_generator(val_data, steps = 2)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# get_ipython().system(u'ls models')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "for model_name in ['model8.h5','model7.h5']:\n",
      "    model = load_model('models/'+model_name)\n",
      "    print('Model: {}'.format(model_name))\n",
      "    model.fit_generator(train_data, epochs = 1, validation_data = val_data)\n",
      "#     loss, accuracy = model.evaluate_generator(val_data)\n",
      "#     print('Model: {} Loss: {} Accuracy: {}'.format(model_name, loss, accuracy))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# from keras.callbacks import *\n",
      "import keras.callbacks.TensorBoard as tb\n",
      "# import tensorflow as tf\n",
      "# import tf.TensorBoard as tb\n",
      "\n",
      "from datetime import datetime\n",
      "now = str(datetime.now())\n",
      "timestamp = now[:10]+'-'+now[11:19]\n",
      "\n",
      "log_dir = 'logs/'+timestamp\n",
      "if not os.path.exists(log_dir):\n",
      "    os.mkdir(log_dir)\n",
      "tensorboard_callback = tb(log_dir)\n",
      "\n",
      "model.fit_generator(train_data, epochs = 100, validation_data = val_data, callbacks = [tensorboard_callback])\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# test_image = imread('data/data/test/test1.jpeg')\n",
      "# print(test_image.shape)\n",
      "# test_images = np.array([test_image])\n",
      "# test_image = datagen.flow\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# from scipy.misc import imresize\n",
      "import cv2\n",
      "\n",
      "test_image = cv2.imread('data/data/test/test3.jpeg')\n",
      "# test_image = test_image.reshape(256, 256, 3)\n",
      "new_shape = (256, 256)\n",
      "\n",
      "resized_image = cv2.resize(test_image, new_shape)\n",
      "resized_image = resized_image/255.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# test_image = resized_image\n",
      "# cv2.imshow('image', resized_image)\n",
      "#cv2.waitKey(0)\n",
      "#cv2.destroyAllWindows()\n",
      "# print(test_image.shape)\n",
      "test_images = np.array([resized_image])\n",
      "# datagen2 = ImageDataGenerator(preprocessing_function = lambda a=test_image,b=new_shape:imresize(a,b))\n",
      "# test_image = datagen.flow(test_images)\n",
      "# batchX = test_image.next()\n",
      "# print(batchX.shape)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "model.predict(test_images)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# from keras.models import load_model\n",
      "# model = load_model('models/model1.h5')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Test stuff\n",
      "from keras.preprocessing.image import *\n",
      "\n",
      "img_file_path = 'data/data/train/glass/glass100.jpg'\n",
      "img = load_img(img_file_path, target_size=(256, 256))\n",
      "\n",
      "print(type(img))\n",
      "print(img.format)\n",
      "print(img.mode)\n",
      "print(img.size)\n",
      "\n",
      "# img.show()\n",
      "img1 = img_to_array(img)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "datagen = ImageDataGenerator(rescale = 1.0)\n",
      "\n",
      "generator = datagen.flow_from_directory('data/data/train', class_mode='categorical', batch_size = 32, target_size=(256,256), shuffle=False)\n",
      "# val_data = datagen.flow_from_directory('data/data/val', class_mode='categorical', target_size=(256,256), shuffle=False)\n",
      "# val_it = datagen.flow_from_directory('data/validation/', class_mode='binary')\n",
      "# test_it = datagen.flow_from_directory('data/test/', class_mode='binary')\n",
      "# confirm the iterator works\n",
      "print(generator.filenames[0])\n",
      "batchX, batchy = generator.next()\n",
      "# print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
      "# print(batchX[1].shape)\n",
      "# # print(batchy[1])\n",
      "img2 = batchX[0]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "print(img1.all() == img2.all())\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "model2.summary()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#check whether you're predicting the same thing everytime!!\n",
      "import cv2\n",
      "import os\n",
      "import numpy as np\n",
      "from keras.preprocessing.image import *\n",
      "from pprint import pprint\n",
      "\n",
      "# resized_images = []\n",
      "# dir_name = 'data/data/test'\n",
      "# for img_name in os.listdir(dir_name)[:20]:\n",
      "#     print('image_name: {}'.format(img_name))\n",
      "# #     test_image = cv2.imread(dir_name+'/'+img_name)\n",
      "    \n",
      "# #     img_file_path = 'data/data/train/glass/glass100.jpg'\n",
      "#     img_file_path = dir_name+'/'+img_name\n",
      "#     img = load_img(img_file_path, target_size=(256, 256))\n",
      "#     test_image = img\n",
      "# #     print(type(img))\n",
      "# #     print(img.format)\n",
      "# #     print(img.mode)\n",
      "# #     print(img.size)\n",
      "\n",
      "#     # img.show()\n",
      "#     img1 = img_to_array(img)\n",
      "\n",
      "# #     new_shape = (256, 256)\n",
      "# #     resized_image = cv2.resize(test_image, new_shape)\n",
      "# #     resized_image = resized_image/255.0\n",
      "#     resized_images.append(img1)\n",
      "\n",
      "# test_images = np.array(resized_images)\n",
      "\n",
      "# datagen = ImageDataGenerator(rescale = 1.0, width_shift_range=10.0, vertical_flip=True, height_shift_range = 10.0, rotation_range = 10.0)\n",
      "# batch_size = 4\n",
      "# datagen = ImageDataGenerator(rescale=1.0)\n",
      "# generator = datagen.flow_from_directory('data/data-real-world', shuffle=False, batch_size=batch_size)\n",
      "# i = 0\n",
      "\n",
      "# filenames = generator.filenames\n",
      "\n",
      "# for batchX, batchy in generator:\n",
      "    \n",
      "#     bottleneck_test = base.predict(batchX)\n",
      "#     predictions = model2.predict(bottleneck_test)\n",
      "    \n",
      "#     predictions2 = [prediction.argmax() for prediction in predictions]\n",
      "#     predictions2 = [order[prediction2] for prediction2 in predictions2]\n",
      "#     try:\n",
      "#         x1 = (filenames[i:i+batch_size])\n",
      "#     except:\n",
      "#         x1 = (filenames[i:])\n",
      "#     x2 = (predictions2)\n",
      "#     for x1_item, x2_item in zip(x1, x2):\n",
      "#         print('image: {} \\tprediction: {}\\tfile: {}'.format(x1_item.split('/')[0], x2_item, x1_item.split('/')[1]))\n",
      "#     if i >= len(generator.filenames) / batch_size:\n",
      "#         break\n",
      "#     i+=1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# bottleneck_test = base.predict(test_images)\n",
      "\n",
      "# predictions = model2.predict(bottleneck_test)\n",
      "# predictions2 = [prediction.argmax() for prediction in predictions]\n",
      "# predictions2 = [order[prediction2] for prediction2 in predictions2]\n",
      "# print(predictions2)\n",
      "# print(predictions)\n",
      "\n",
      "\n",
      "# loss, accuracy = model2.evaluate_generator(val_data)\n",
      "# print('Model: {} Loss: {} Accuracy: {}'.format(model_name, loss, accuracy))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Augmentation\n",
      "\n",
      "import os\n",
      "datagen = ImageDataGenerator(rescale = 1.0, width_shift_range=30.0, vertical_flip=True, height_shift_range = 30.0, rotation_range = 10.0, horizontal_flip=True)\n",
      "\n",
      "batch_size = 16\n",
      "generator = datagen.flow_from_directory('data/data-real-world2/', shuffle=False, batch_size = batch_size)\n",
      "# i = 0\n",
      "\n",
      "j = 0\n",
      "for i in range(40):\n",
      "    print(i)\n",
      "    batchX, batchy = generator.next()\n",
      "#     print(type(batchX[0]))\n",
      "#     img = array_to_img(batchX[0])\n",
      "#     print(type(img))\n",
      "    for batchX_item, batchy_item in zip(batchX, batchy):\n",
      "#         print(batchy_item)\n",
      "        class_name = order[np.argmax(batchy_item)]\n",
      "#         print(class_name)\n",
      "        path = 'data/tmp/'+class_name+'/'\n",
      "        if not os.path.exists(path):\n",
      "            os.mkdir(path)\n",
      "        print('saving: {}'.format(path+'augmented_'+class_name+str(j)+'.jpg'))\n",
      "        save_img(path+'augmented_multiple_'+class_name+str(j)+'.jpg', batchX_item)\n",
      "        print('done')\n",
      "        j+=1\n",
      "# filenames = generator.filenames\n",
      "\n",
      "# for batchX, batchy in generator:\n",
      "    \n",
      "#     bottleneck_test = base.predict(batchX)\n",
      "#     predictions = model2.predict(bottleneck_test)\n",
      "    \n",
      "#     predictions2 = [prediction.argmax() for prediction in predictions]\n",
      "#     predictions2 = [order[prediction2] for prediction2 in predictions2]\n",
      "#     try:\n",
      "#         x1 = (filenames[i:i+batch_size])\n",
      "#     except:\n",
      "#         x1 = (filenames[i:])\n",
      "#     x2 = (predictions2)\n",
      "#     for x1_item, x2_item in zip(x1, x2):\n",
      "#         print('image: {} \\tprediction: {}\\tfile: {}'.format(x1_item.split('/')[0], x2_item, x1_item.split('/')[1]))\n",
      "#     if i >= len(generator.filenames) / batch_size:\n",
      "#         break\n",
      "#     i+=1\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "# bottleneck_test = base.predict(test_images)\n",
      "\n",
      "# predictions = model2.predict(bottleneck_test)\n",
      "# predictions2 = [prediction.argmax() for prediction in predictions]\n",
      "# predictions2 = [order[prediction2] for prediction2 in predictions2]\n",
      "# print(predictions2)\n",
      "# print(predictions)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}